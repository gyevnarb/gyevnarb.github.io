---
layout: about
title: about
permalink: /
subtitle: PhD student in AI safety and explainable AI

profile:
  align: right
  image: prof_pic.jpg
  image_circular: true # crops the image to make it circular
  more_info: PhD student in safe and explainable AI
news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

Hi, I am Bálint. Thanks for checking on my home page! ([Bluesky](https://bsky.app/profile/gbalint.bsky.social)) <br />
_(My name is pronounced BAH-lint [baːlint])_

My primary research area is _explainable multi-agent reinforcement learning_.
I like to describe this as the study of _giving interacting AI agents the ability to explain themselves._

I am primarily interested in how we can explain complex emergent behaviour in multi-agent systems (MAS) via the use of counterfactual reasoning, and how this in turn can be used to calibrate trust and verify the safety of MAS.

I also work on bridging the epistemic foundations and research problems of AI ethics and safety to foster cross-disciplinary collaboration.

I am a member of the [Autonomous Agents Research Group](https://agents-lab.org/), supervised by [Shay Cohen](https://homepages.inf.ed.ac.uk/scohen/) and [Chris Lucas](https://homepages.inf.ed.ac.uk/clucas2/). I was previously supervised by [Stefano Albrecht](https://agents-lab.org/stefano-albrecht/).


<!-- <br />

<img src="assets/img/background.jpg" alt="View of a corrie in the Scottish Highlands" width="100%" />
_View of a corrie from Beinn Bhan near Applecross, Scotland shot by me._ -->

<br />